{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bq2hIzlMUCw_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a prediction model with help of the PyTorch LSTM framework to forecast timeseries.\n",
    "\n",
    "Source: https://www.geeksforgeeks.org/time-series-forecasting-using-pytorch/\n",
    "\"\"\"\n",
    "\n",
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "from imports import *\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "def saveAsJson (data:dict, name:str) -> None:\n",
    "    with open(f\"{name}.json\", \"w+\") as outfile: \n",
    "        json.dump(data, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a IoT-Server object and grab the related timeseries from the InfluxDB database\n",
    "\n",
    "# Inverter 2\n",
    "inv2 = IotGrabber()\n",
    "inv2.setDevices([\"INV2\", \"TEMP\", \"HUM\"])\n",
    "inv2.setTimeAbsStart(\"2024-06-04T00:00:00Z\")\n",
    "inv2.setTimeAbsEnd  (\"2024-09-12T23:59:00Z\")\n",
    "df_inv2 = inv2.get_df()\n",
    "df_inv2.rename(columns=lambda x: x.replace('INV2', 'POWER'), inplace=True)\n",
    "\n",
    "# Power measurement 'serverroom'\n",
    "pm_serverroom = IotGrabber()\n",
    "pm_serverroom.setDevices([\"SHELLY_API_SERVERROOM_POWER\"])\n",
    "pm_serverroom.setTimeAbsStart(\"2024-07-16T00:00:00Z\")\n",
    "pm_serverroom.setTimeAbsEnd  (\"2024-10-13T23:59:00Z\")\n",
    "df_serverroom = pm_serverroom.get_df()\n",
    "df_serverroom.rename(columns=lambda x: x.replace('SHELLY_API_SERVERROOM_POWER', 'POWER'), inplace=True)\n",
    "\n",
    "# Power measurement 'floor'\n",
    "pm_floor = IotGrabber()\n",
    "pm_floor.setDevices([\"SHELLY_API_FLOOR_POWER\"])\n",
    "pm_floor.setTimeAbsStart(\"2024-07-16T00:00:00Z\")\n",
    "pm_floor.setTimeAbsEnd  (\"2024-10-13T23:59:00Z\")\n",
    "df_floor = pm_floor.get_df()\n",
    "df_floor.rename(columns=lambda x: x.replace('SHELLY_API_FLOOR_POWER', 'POWER'), inplace=True)\n",
    "\n",
    "\n",
    "timeseries = [df_inv2, df_serverroom, df_floor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLstmModel (df:pd.DataFrame,\n",
    "                       name:str) -> torch:\n",
    "    \"\"\"Generate a LSTM model from a timeseries in a pd.Dataframe and save it\"\"\"\n",
    "\n",
    "    # Generate data sets\n",
    "    # Train test split\n",
    "    training_data_len = math.ceil(len(df) * .9)\n",
    "\n",
    "    # Splitting the dataset\n",
    "    train_data = df[:training_data_len].iloc[:, :1]\n",
    "    test_data = df[training_data_len:].iloc[:, :1]\n",
    "    dataset_train = train_data.POWER.values\n",
    "    dataset_train = np.reshape(dataset_train, (-1, 1)) # (-1,1) --> n-rows, 1 col\n",
    "    # print(dataset_train.shape)\n",
    "\n",
    "    # Selecting Open Price values\n",
    "    dataset_test = test_data.POWER.values\n",
    "    # Reshaping 1D to 2D array\n",
    "    dataset_test = np.reshape(dataset_test, (-1, 1))\n",
    "    # print(dataset_test.shape)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    # Scaling dataset\n",
    "    scaled_train = scaler.fit_transform(dataset_train)\n",
    "    # print(scaled_train[:5])\n",
    "\n",
    "    # Normalizing values between 0 and 1\n",
    "    scaled_test = scaler.transform(dataset_test)\n",
    "    # print(scaled_test[:5])\n",
    "\n",
    "    # Create sequences and labels for training data\n",
    "    sequence_length = 50  # Number of time steps to look back\n",
    "    X_train, y_train = [], []\n",
    "    for i in range(len(scaled_train) - sequence_length):\n",
    "        X_train.append(scaled_train[i:i + sequence_length])\n",
    "        y_train.append(scaled_train[i + sequence_length])  # Predicting the value right after the sequence\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "    # print(X_train.shape, y_train.shape)\n",
    "\n",
    "    # Create sequences and labels for testing data\n",
    "    sequence_length = 30  # Number of time steps to look back\n",
    "    X_test, y_test = [], []\n",
    "    for i in range(len(scaled_test) - sequence_length):\n",
    "        X_test.append(scaled_test[i:i + sequence_length])\n",
    "        y_test.append(scaled_test[i + sequence_length])  # Predicting the value right after the sequence\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    # ---------------------------------------------------- #\n",
    "\n",
    "    # Create the LSTM model\n",
    "    class LSTMModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):\n",
    "            super(LSTMModel, self).__init__()\n",
    "            self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "            self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out, _ = self.lstm(x)\n",
    "            out = self.linear(out[:, -1, :])\n",
    "            return out\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "\n",
    "    input_size = 1\n",
    "    num_layers = 3  # Increased number of layers (3)\n",
    "    hidden_size = 128  # Increased number of hidden units (128)\n",
    "    output_size = 1\n",
    "    dropout = 0.2  # Added dropout for regularization\n",
    "\n",
    "    model = LSTMModel(input_size, hidden_size, num_layers, dropout).to(device)\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0)  # Learning rate\n",
    "\n",
    "    batch_size = 32*1  # Adjusted batch size (32)\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    num_epochs = 10  # Increased number of epochs 100\n",
    "    train_hist = []\n",
    "    test_hist = []\n",
    "\n",
    "    print(\"Start epochs...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        predictions_test_all = [] # added\n",
    "        print(f\"Epoche: {epoch+1}\")\n",
    "        total_loss = 0.0\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            predictions = model(batch_X)\n",
    "            loss = loss_fn(predictions, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        train_hist.append(average_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_test_loss = 0.0\n",
    "\n",
    "            for batch_X_test, batch_y_test in test_loader:\n",
    "                batch_X_test, batch_y_test = batch_X_test.to(device), batch_y_test.to(device)\n",
    "                predictions_test = model(batch_X_test)\n",
    "                predictions_test_cpu = predictions_test.cpu().numpy()[0, 0] # added\n",
    "                predictions_test_all.append(predictions_test_cpu)           # added\n",
    "                test_loss = loss_fn(predictions_test, batch_y_test)\n",
    "\n",
    "                total_test_loss += test_loss.item()\n",
    "\n",
    "            average_test_loss = total_test_loss / len(test_loader)\n",
    "            test_hist.append(average_test_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}, Test Loss: {average_test_loss:.4f}')\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "    # Save model\n",
    "    model_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    torch.save(model.state_dict(), f\"{model_time}-{name}.model\")\n",
    "\n",
    "            \n",
    "    print(f\"Model generation done\")      \n",
    "\n",
    "    x = np.linspace(1,num_epochs,num_epochs)\n",
    "    plt.plot(x,train_hist,scalex=True, label=\"Training loss\")\n",
    "    plt.plot(x, test_hist, label=\"Test loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # -------------------------------- #\n",
    "    \n",
    "    # Validate\n",
    "    num_forecast_steps = 30*1 # (30)\n",
    "    sequence_to_plot = X_test.squeeze().cpu().numpy()\n",
    "    historical_data = sequence_to_plot[-1]\n",
    "\n",
    "    forecasted_values = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_forecast_steps):\n",
    "            historical_data_tensor = torch.as_tensor(historical_data).view(1, -1, 1).float().to(device)\n",
    "            predicted_value = model(historical_data_tensor).cpu().numpy()[0, 0]\n",
    "            forecasted_values.append(predicted_value)\n",
    "            historical_data = np.roll(historical_data, shift=-1)\n",
    "            historical_data[-1] = predicted_value\n",
    "\n",
    "    last_date = test_data.index[-1]\n",
    "    future_dates = pd.date_range(start=last_date + pd.Timedelta(1, unit='m'), periods=num_forecast_steps, freq=\"1min\") # add 1 min steps to the df\n",
    "\n",
    "    forecasted = scaler.inverse_transform(np.array(forecasted_values).reshape(-1, 1)).flatten()\n",
    "    predicted = pd.DataFrame()\n",
    "    predicted.insert(0, \"Date\", future_dates)\n",
    "    predicted.insert(1, \"Predict\", forecasted)\n",
    "    predicted.set_index(\"Date\", inplace=True)\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = [14, 4]\n",
    "\n",
    "    # Plot complete data\n",
    "    # plt.plot(df.index[:], df.POWER, label=\"Complete Data\", color=\"b\")\n",
    "\n",
    "    # Plot training data\n",
    "    # plt.plot(train_data.index[:], train_data[:], label=\"Training Data\", color=\"g\")\n",
    "\n",
    "    # Plot test data\n",
    "    # plt.plot(test_data.index[:], test_data[:], label=\"Test Data\", color=\"r\")\n",
    "\n",
    "    # Plot predicted data\n",
    "    # plt.plot(predicted.index[:], predicted[:], label='Predicted', color='g')\n",
    "\n",
    "    # Misc Plots\n",
    "    # plt.plot(test_data.index[-num_forecast_steps:], test_data[-num_forecast_steps:], label='actual values', color='green')\n",
    "    # plt.plot(test_data.index[-1:].append(future_dates), np.concatenate([test_data[-1:], scaler.inverse_transform(np.array(forecasted_values).reshape(-1, 1)).flatten()]), label='forecasted values', color='red')\n",
    "\n",
    "\n",
    "    # plt.xlabel('Time Step')\n",
    "    # plt.ylabel('Value')\n",
    "    # plt.legend()\n",
    "    # plt.title('Time Series Forecasting')\n",
    "    # plt.grid(True)\n",
    "    # plt.ylim(-100,6000)\n",
    "    # plt.show()\n",
    "\n",
    "    # Evaluate the model and calculate RMSE and R² score\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_predictions = []\n",
    "        for batch_X_test in X_test:\n",
    "            batch_X_test = batch_X_test.to(device).unsqueeze(0)  # Add batch dimension\n",
    "            test_predictions.append(model(batch_X_test).cpu().numpy().flatten()[0])\n",
    "\n",
    "    test_predictions = np.array(test_predictions)\n",
    "\n",
    "    # Calculate RMSE and R² score\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.cpu().numpy(), test_predictions))\n",
    "    r2 = r2_score(y_test.cpu().numpy(), test_predictions)\n",
    "\n",
    "    # print(f'RMSE: {rmse:.4f}')\n",
    "    # print(f'R² Score: {r2:.4f}')\n",
    "\n",
    "    test_predictions_all = scaler.inverse_transform(np.array(test_predictions).reshape(-1, 1)).flatten()\n",
    "    # plt.plot(test_data.index[30:], test_data.POWER[30:], label=\"Test Data\", color=\"b\")\n",
    "    # plt.plot(test_data.index[30:], test_predictions_all, label=\"Test Data_predicted\", color='green')\n",
    "    # plt.show()\n",
    "\n",
    "    dPred = test_data.POWER[30:]- test_predictions_all\n",
    "\n",
    "    results = {\"test_data\": test_data,\n",
    "               \"test_prediction_data\": test_predictions_all,\n",
    "               \"predicted\": predicted,\n",
    "               \"num_forecast_steps\": num_forecast_steps,\n",
    "               \"dPred\": dPred,\n",
    "               \"rmse\": rmse,\n",
    "               \"r2\": r2\n",
    "               }\n",
    "\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv2_model, inv2_lstm_results = generateLstmModel(df_inv2, \"INV2\")\n",
    "serverroom_model, serverroom_results = generateLstmModel(df_serverroom, \"Serverroom\")\n",
    "floor_model, floor_results = generateLstmModel(df_floor, \"Floor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverter2\n",
    "errors = {\"rmse\": str(inv2_lstm_results[\"rmse\"]), \"r2\": str(inv2_lstm_results[\"r2\"])}\n",
    "saveAsJson(errors, \"LSTM-Inverter2\")\n",
    "test_data = inv2_lstm_results[\"test_data\"]\n",
    "test_prediction_data = inv2_lstm_results[\"test_prediction_data\"]\n",
    "\n",
    "plt.plot(test_data.index[30:], test_data.POWER[30:], label=\"Test Data\", color=\"b\")\n",
    "plt.plot(test_data.index[30:], test_prediction_data, label=\"Test Data_predicted\", color='green')\n",
    "plt.show()\n",
    "\n",
    "# Serverroom\n",
    "errors = {\"rmse\": str(serverroom_results[\"rmse\"]), \"r2\": str(serverroom_results[\"r2\"])}\n",
    "saveAsJson(errors, \"LSTM-Serverroom\")\n",
    "test_data = serverroom_results[\"test_data\"]\n",
    "test_prediction_data = serverroom_results[\"test_prediction_data\"]\n",
    "\n",
    "plt.plot(test_data.index[30:], test_data.POWER[30:], label=\"Test Data\", color=\"b\")\n",
    "plt.plot(test_data.index[30:], test_prediction_data, label=\"Test Data_predicted\", color='green')\n",
    "plt.show()\n",
    "\n",
    "# Floor\n",
    "errors = {\"rmse\": str(floor_results[\"rmse\"]), \"r2\": str(floor_results[\"r2\"])}\n",
    "saveAsJson(errors, \"LSTM-Floor\")\n",
    "test_data = floor_results[\"test_data\"]\n",
    "test_prediction_data = floor_results[\"test_prediction_data\"]\n",
    "\n",
    "plt.plot(test_data.index[30:], test_data.POWER[30:], label=\"Test Data\", color=\"b\")\n",
    "plt.plot(test_data.index[30:], test_prediction_data, label=\"Test Data_predicted\", color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prediction = pd.DataFrame({\"Date\":test_data.index[30:],\n",
    "                                   \"Test\":test_data.POWER[30:],\n",
    "                                   \"Predict\":test_prediction_data,\n",
    "                                   \"error\":test_data.POWER[30:]-test_prediction_data})\n",
    "\n",
    "df_test_prediction.set_index(\"Date\", inplace=True)\n",
    "df_test_prediction.to_csv(\"LSTM-Serverroom.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prediction.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
